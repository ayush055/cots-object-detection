{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from shutil import copyfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./tensorflow-great-barrier-reef/train.csv')\n",
    "train['pos'] = train.annotations != '[]'\n",
    "fold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"./\"\n",
    "DATASET_PATH = os.path.join('yolo_data', f'fold{str(fold)}', 'images')\n",
    "LABELS_PATH = os.path.join('yolo_data', f'fold{str(fold)}', 'labels')\n",
    "\n",
    "os.makedirs(os.path.join(HOME_DIR, 'yolo_data', f'fold{str(fold)}'))\n",
    "\n",
    "for path in [DATASET_PATH, LABELS_PATH]:\n",
    "    os.makedirs(os.path.join(HOME_DIR, path))\n",
    "    os.makedirs(os.path.join(HOME_DIR, path, 'train'))\n",
    "    os.makedirs(os.path.join(HOME_DIR, path, 'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharp_filter = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n",
    "# def gamma_enhance(img, gamma=1.0):\n",
    "#     lookUpTable = np.empty((1,256), np.uint8)\n",
    "#     for i in range(256):\n",
    "#         lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
    "#     return cv2.LUT(img, lookUpTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocessed Images\n",
    "\n",
    "# for i in tqdm(range(len(train))):\n",
    "#     row = train.loc[i]\n",
    "#     img = cv2.imread(row.image_path)\n",
    "#     # img = gamma_enhance(cv2.filter2D(img, -1, sharp_filter), gamma=2)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     if row.video_id != fold:\n",
    "#         cv2.imwrite(f'{HOME_DIR}{DATASET_PATH}/train/{row.image_id}.jpg', img)\n",
    "#         # copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}/train/{row.image_id}.jpg')\n",
    "#     else:\n",
    "#         cv2.imwrite(f'{HOME_DIR}{DATASET_PATH}/val/{row.image_id}.jpg', img)\n",
    "#         # copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}/val/{row.image_id}.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos = []\n",
    "for i, x in train.iterrows():\n",
    "    if x.video_id == fold:\n",
    "        mode = 'val'\n",
    "    else:\n",
    "        # train\n",
    "        mode = 'train'\n",
    "        if not x.pos: continue\n",
    "        # val\n",
    "    copyfile(f'./tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n",
    "                f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n",
    "    if not x.pos:\n",
    "        continue\n",
    "    r = ''\n",
    "    anno = eval(x.annotations)\n",
    "    for an in anno:\n",
    "#            annos.append(an)\n",
    "        r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n",
    "                                        (an['y'] + an['height'] / 2) / 720,\n",
    "                                        an['width'] / 1280, an['height'] / 720)\n",
    "    with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n",
    "        fp.write(r)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cec74ebff8b098a626fe5bffb7f4bb9a9a8a54a30de8c9492799db6d88b4598"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('cots2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
